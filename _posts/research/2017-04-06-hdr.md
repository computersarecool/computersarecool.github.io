---
category: research

meta:
  keywords: "HDR, Photography, Camera Response Function, Image Processing, Research, Computational Photography"

project:
  title: "HDR // Camera Response Recovery"
  preview: "video"
  preview_main: "/assets/media/research/hdr/preview.webm"
  preview_backup: "/assets/media/research/hdr/logo.mp4"

mathjax: true

media:
  - type: image
    url: "/assets/media/research/hdr/first.png"
    alt: "HDR image created from a radiance map"

  - type: image
    url: "/assets/media/research/hdr/second.png"
    alt: "Image acquisition pipeline and false color image of radiance map"

  - type: image
    url: "/assets/media/research/hdr/third.png"
    alt: "Images at different shutter speeds"

sections:
  -
    - p: 'Today High Dynamic Range Images, or HDRI are commonplace. Many smartphones contain built-in support for HDR images and 
some even default to using HDR to capture images.'

    - p: 'Fundamentally dealing with HDR data is all about capturing the radiance of the scene. A naive thought would be that 
pixels appearing twice as bright in an image relate to areas in the photographed scene with twice as much radiance.'

    - p: 'The second featured image shows this is not the case. A tremendous range of radiance values have to be mapped to 
a significantly smaller range of pixel intensities. The image also shows the pipeline that creates this non-linear mapping.'

    - p: 'For many reasons this is not true, and one challenging reason is the non-linear response function of cameras. This 
function is not usually published by camera makers who consider it a trade secret.'

    - p: 'Recovering this function allows more than just the the common "HDR look" (and the hyper-realistic 
tone-mapped style), including being able to achieve more realistic motion-blur, color-correction and edge detection in 
images.'

  -
    - p: 'With a stack of aligned images at different exposures, the non-linear response function can be recovered with the 
following formula.'

    - p: '$$Z_{ij} = f(E\Delta t)$$'

    - p: 'Where $i$ indexes over pixel locations and $j$ indexes over the different equations.'

  -
    - p: 'With some manipulation this simplifies to:'

    - p: '$$ g(Z_{ij}) = \ln E_i + \ln \Delta t_j $$ Where $g = \ln f^{-1}$'

    - p: 'Written in this form $g$ (and therefore eventually $f$) can be recovered up to a scale by using the $SVD$ to minimize 
a related objective function.'
  
    - p: 'With this function recovered the radiance can be visualized a number of ways (for instance usually by scaling the radiance
to the display device).'
      
    - p: 'This project implements the following academic papers:'

    - ul:
      - '<a href="https://dl.acm.org/doi/10.1145/1401132.1401174">Recovering High Dynamic Range Radiance Maps from 
        Photographs</a> by Paul E. Debevec and Jitendra M. Malik'

      - '<a href="https://ieeexplore.ieee.org/document/1240119">Determining the camera response from images: what is knowable?
        </a> M.D. Grossberg, S.K. Nayar'

      - '<a href="https://ieeexplore.ieee.org/document/1323796">Modeling the space of camera response functions</a> M.D. Grossberg, S.K. Nayar'
---